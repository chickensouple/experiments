import numpy as np
import copy
import time

from tree import Tree
from game_base import GameBase, GameActor

class MinMaxNodeState(object):
    def __init__(self,
        game_state,
        minmax_value,
        optimal_action):
        self.game_state = game_state
        self.minmax_value = minmax_value
        self.optimal_action = optimal_action

class MinMaxSearchTree(object):
    """
    MinMax Search Tree
    """
    def __init__(self, game):
        """
        ctor for min max search tree.

        Arguments:
            game {GameBase} -- A game object that will be used and mutated by the minmax tree search.
                Don't the game outside of this class as it will be manipulated within here.
        """
        self.tree = Tree()
        self.game = game

    def search(self, game_state, player):
        """
        Perform MinMax search and return the search tree.
        The returned search tree will contain a tuple of data at each node.
        This tuple consists of (game_state, minmax_value, optimal_action)

        Arguments:
            game_state {np.array} -- state of the game as returned by ttt.get_state()
            player {which player to solve minmax tree for} -- PLAYER1 or PLAYER2
        """
        # clear out any previous searches
        self.tree.reset()

        # Insert the parent node
        root_idx = self.tree.insert_node(MinMaxNodeState(game_state, None, None), None)

        # Start expanding from parent node
        self._expand_node(root_idx, player)
        return self.tree

    def _expand_node(self, node_idx, player):
        # get possible actions
        node_data = self.tree.get_node_data(node_idx)
        self.game.set_state(node_data.game_state)
        curr_player = self.game.get_curr_player()
        actions = self.game.get_valid_actions()

        # If we have reached a leaf node, get the value and return
        # 1 for winning, -1 for losing, 0 for tie
        if len(actions) == 0:
            val = self.game.get_outcome(player)
            node_data.minmax_value = val
            self.tree.update_node_data(node_idx, node_data)
            return val

        # Recursively expand each child node
        # and collect the minmax values
        minmax_vals = []
        for action in actions:
            self.game.set_state(node_data.game_state)
            self.game.step(action)

            new_node_idx = self.tree.insert_node(MinMaxNodeState(self.game.get_state(), None, None), node_idx)
            val = self._expand_node(new_node_idx, player)
            minmax_vals.append(val)

        # Compute minimum or maximum of values depending on what level the
        # search is currently on
        if player == curr_player:
            val_idx = np.argmax(minmax_vals)
        else:
            val_idx = np.argmin(minmax_vals)
        val = minmax_vals[val_idx]
        opt_action = actions[val_idx]

        # update the expanded node with the value and optimal action
        node_data.minmax_value = val
        node_data.optimal_action = opt_action
        self.tree.update_node_data(node_idx, node_data)
        return val


class OptimalActor(GameActor):
    """
    Class to play tic tac toe using MinMax search results.
    """
    def __init__(self, optimal_data):
        """
        Creates the min max player.

        Arguments:
            optimal_data {np.array} -- The numpy array generated by OptimalActor.generate_optimal_data() 
        """
        self.optimal_data = optimal_data

    def get_action(self, game_state):
        """
        Get an action at a particular game state.
        """
        idx = OptimalActor._state_to_idx(game_state)
        return tuple(self.optimal_data[idx, :])

    _POWERS_3 = np.power(3, np.arange(9))
    _PLAYER_OFFSET = np.sum(2 * _POWERS_3) + 1
    _MAX_STATES = _PLAYER_OFFSET + np.sum(2 * _POWERS_3)
    @staticmethod
    def _state_to_idx(state):
        idx = np.sum(OptimalActor._POWERS_3 * state[:9])
        idx += (state[9] == GameBase.Player.PLAYER2) * OptimalActor._PLAYER_OFFSET
        return idx

    @staticmethod
    def generate_optimal_data():
        """
        Generates numpy array of optimal moves.
        It will be an (N, 2) array. Where the i'th row is the optimal action 
        for the i'th state. The states are indexed by flattening the state using
        _state_to_idx().
        """
        ttt = TicTacToe()
        ttt_search = TicTacToe()
        search_tree = MinMaxSearchTree(ttt_search)

        # Run search for the various scenarios where the minmax player has to go first
        # or second reacting to various first moves.
        tree_list = []
        tree_list.append(copy.deepcopy(search_tree.search(ttt.get_state(), GameBase.Player.PLAYER1)))
        actions = ttt.get_valid_actions()
        initial_state = ttt.get_state()
        for action in actions:
            ttt.set_state(initial_state)
            ttt.step(action)
            tree_list.append(copy.deepcopy(search_tree.search(ttt.get_state(), GameBase.Player.PLAYER2)))

        # Take the search trees and condense the optimal actions into a numpy array
        optimal_actions = np.ones((OptimalActor._MAX_STATES, 2), dtype=np.int8) * -1
        for tree in tree_list:
            for node in tree.nodes:
                idx = OptimalActor._state_to_idx(node.game_state)
                if node.optimal_action != None:
                    optimal_actions[idx, :] = node.optimal_action
        return optimal_actions

if __name__ == "__main__":
    import argparse
    import pickle
    from tictactoe import TicTacToe, TicTacToeHumanActor
    from game_base import run_game

    parser = argparse.ArgumentParser(
        description="MinMax TicTacToe Player. \
                     Use *generate* option to generate perform a search and cache the optimal actions.\
                     Then use the *play* option to read in the cached data and play a game against the computer.")
    parser.add_argument(
        "--file",
        action="store",
        type=str,
        default="/tmp/minmax_cache.npy",
        help="File to store/load search trees.")
    subparser = parser.add_subparsers(
        help="Generate tree or play game.",
        dest="cmd")
    generate_subparser = subparser.add_parser("generate",
        help="Generate Search Trees and save them.")

    play_subparser = subparser.add_parser("play",
        help="Play against MinMax computer.")
    play_subparser.add_argument(
        "--player",
        action="store",
        type=int,
        default=1,
        choices=[1, 2],
        help="choose to play as player 1 or 2")
    args = parser.parse_args()

    if args.cmd == "generate":
        start_time = time.clock()
        optimal_data = OptimalActor.generate_optimal_data()
        end_time = time.clock()
        print("Total time for full MinMax Tree Search: {} seconds".format(end_time - start_time))

        np.save(args.file, optimal_data)
    else:
        optimal_data = np.load(args.file)

        human_actor = TicTacToeHumanActor()
        minmax_actor = OptimalActor(optimal_data)

        ttt = TicTacToe()
        human_actor.print_help()
        if args.player == 1:
            result = run_game(ttt, human_actor, minmax_actor)
        else:
            result = run_game(ttt, minmax_actor, human_actor)
        ttt.print_board()
        print("End Game Status: {}".format(result["game_status"].name))

